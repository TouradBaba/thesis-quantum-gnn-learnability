{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4417b4e5-96a3-4659-963b-663ab7743ea5",
   "metadata": {},
   "source": [
    "# Extrapolation Data Generation\n",
    "\n",
    "This notebook generates 6-qubit quantum circuit datasets for evaluating extrapolation performance of models trained on smaller circuits (2â€“5 qubits). It constructs both Class A (variational ansatz) and Class B (QAOA-like) circuits under noiseless and hardware-calibrated noisy conditions. Each circuit is converted into a graph-structured data object with engineered node and global features, including gate type, qubit encoding, gate parameters, noise calibrations, and Laplacian positional embeddings (`k=8`).The datasets are saved in a PyTorch Geometric-compatible format and will be used for zero-shot and few-shot extrapolation tests using both Graph Neural Networks and Convolutional Neural Networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2f71461-fc9d-461f-9e04-c1722c0b422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95ab51d5-0e8a-482c-98ad-aa744f6a4e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from qiskit import QuantumCircuit, transpile\n",
    "from qiskit.converters import circuit_to_dag\n",
    "from qiskit_aer import AerSimulator\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService\n",
    "from qiskit_aer.noise import NoiseModel\n",
    "from scipy.sparse.linalg import eigsh\n",
    "import datetime\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c168fa2e-8a99-43d4-b779-efde8a738314",
   "metadata": {},
   "source": [
    "## Global Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fc4a9b2-cea0-4052-a330-95dc25197dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seeds set to 42 (random, numpy, torch)\n"
     ]
    }
   ],
   "source": [
    "def set_global_seeds(seed: int):\n",
    "    \"\"\"\n",
    "    Set global random seeds for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    print(f\"Global seeds set to {seed} (random, numpy, torch)\")\n",
    "\n",
    "# Set default seed\n",
    "set_global_seeds(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645ebd92-2e0b-4329-95ff-70d59f3e431a",
   "metadata": {},
   "source": [
    "## Directory Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86315aa5-e94c-4db1-b845-272e1344d8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_dataset_dir(n_qubits, noise_type, circuit_class=None, root='../datasets'):\n",
    "    \"\"\"\n",
    "    Ensure output directory exists.\n",
    "    If circuit_class is None, create up to noise_type level (for calibration snapshot).\n",
    "    \"\"\"\n",
    "    parts = [root, f\"{n_qubits}-qubit\", noise_type]\n",
    "    if circuit_class:\n",
    "        parts.append(circuit_class)\n",
    "    folder = os.path.join(*parts)\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    return folder\n",
    "\n",
    "\n",
    "def save_dataset(data_list, n_qubits, noise_type, circuit_class, root='../datasets'):\n",
    "    \"\"\"\n",
    "    Save the data_list (list of PyG Data) to disk in the correct directory.\n",
    "    \"\"\"\n",
    "    folder = ensure_dataset_dir(n_qubits, noise_type, circuit_class, root=root)\n",
    "    fname = f\"dataset_{n_qubits}q_{noise_type}_{circuit_class}.pt\"\n",
    "    save_path = os.path.join(folder, fname)\n",
    "    torch.save(data_list, save_path)\n",
    "    print(f\"Saved dataset ({len(data_list)} samples) to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee158884-95d1-4b82-915d-13588499c01a",
   "metadata": {},
   "source": [
    "## Gate Encoding and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1f4ad39-9d52-439b-93c6-d05bae95bdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "GATE_TYPES = ['rx', 'ry', 'rz', 'h', 'x', 'y', 'z', 'cx']\n",
    "GATE_TYPE_IDX = {g: i for i, g in enumerate(GATE_TYPES)}\n",
    "\n",
    "def one_hot_gate(name):\n",
    "    \"\"\"\n",
    "    Return one-hot encoding for the given gate name.\n",
    "    \"\"\"\n",
    "    v = [0.0] * len(GATE_TYPES)\n",
    "    i = GATE_TYPE_IDX.get(name, -1)\n",
    "    if i >= 0: v[i] = 1.0\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38a1608-8cd9-48c2-971a-1bc3881ad841",
   "metadata": {},
   "source": [
    "## Quantum Circuits Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74f1cfce-1c37-4be9-a878-889f68e6a934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_variational_ansatz(n_qubits):\n",
    "    \"\"\"\n",
    "    Variational Ansatz for Class A.\n",
    "    - Uses layers = max(1, n_qubits // 2)\n",
    "    - Sparse entanglement: Alternate neighboring pairs connected\n",
    "    \"\"\"\n",
    "    layers = max(1, n_qubits // 2)\n",
    "    qc = QuantumCircuit(n_qubits)\n",
    "    qubits = list(range(n_qubits))\n",
    "\n",
    "    for _ in range(layers):\n",
    "        random.shuffle(qubits)\n",
    "        for q in qubits:\n",
    "            theta = random.uniform(0, 2 * np.pi)\n",
    "            qc.ry(theta, q)\n",
    "\n",
    "        for i in range(0, n_qubits, 2):\n",
    "            qc.cx(i, (i + 1) % n_qubits)\n",
    "\n",
    "    return qc\n",
    "\n",
    "\n",
    "def generate_qaoa_like(n_qubits):\n",
    "    \"\"\"\n",
    "    QAOA-like Ansatz for Class B.\n",
    "    - Uses p = max(1, n_qubits // 2)\n",
    "    - Sparse entanglement: alternate pairs\n",
    "    \"\"\"\n",
    "    p = max(1, n_qubits // 2)\n",
    "    qc = QuantumCircuit(n_qubits)\n",
    "    qc.h(range(n_qubits))\n",
    "\n",
    "    for _ in range(p):\n",
    "        gamma = random.uniform(0, 2 * np.pi)\n",
    "        for i in range(0, n_qubits, 2):\n",
    "            qc.cx(i, (i + 1) % n_qubits)\n",
    "            qc.rz(2 * gamma, (i + 1) % n_qubits)\n",
    "            qc.cx(i, (i + 1) % n_qubits)\n",
    "\n",
    "        beta = random.uniform(0, 2 * np.pi)\n",
    "        for q in range(n_qubits):\n",
    "            qc.rx(2 * beta, q)\n",
    "\n",
    "    return qc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8723d34f-0f98-4208-976f-06726d4f3601",
   "metadata": {},
   "source": [
    "## Noise Model and Calibration Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d11afe3f-c557-480b-b165-314023ca9848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise_model_and_calib(n_qubits, backend_name=\"ibm_sherbrooke\", noisy=True):\n",
    "    \"\"\"\n",
    "    Get noise model, per-qubit calibration (T1, T2, readout), and gate errors.\n",
    "    Returns:\n",
    "        - noise_model\n",
    "        - per_qubit_calib: List[[T1, T2, readout]]\n",
    "        - per_gate_errors: Dict[str, float] (e.g. 'cx_0_1', 'rx_0')\n",
    "    \"\"\"\n",
    "    if not noisy:\n",
    "        per_qubit_calib = [[0.0, 0.0, 0.0] for _ in range(n_qubits)]\n",
    "        per_gate_errors = {}\n",
    "        for g in GATE_TYPES:\n",
    "            if g == \"cx\":\n",
    "                for q0 in range(n_qubits):\n",
    "                    for q1 in range(n_qubits):\n",
    "                        if q0 != q1:\n",
    "                            per_gate_errors[f\"cx_{q0}_{q1}\"] = 0.0\n",
    "            else:\n",
    "                for q in range(n_qubits):\n",
    "                    per_gate_errors[f\"{g}_{q}\"] = 0.0\n",
    "        return None, per_qubit_calib, per_gate_errors\n",
    "\n",
    "    try:\n",
    "        token = os.getenv(\"IBM-QUANTUM-THESIS-WORK\")\n",
    "        if not token:\n",
    "            raise RuntimeError(\"IBM-QUANTUM-THESIS-WORK token not set.\")\n",
    "\n",
    "        QiskitRuntimeService.save_account(token=token, instance=\"THESIS-WORK\", overwrite=True)\n",
    "        service = QiskitRuntimeService(channel=\"ibm_quantum_platform\")\n",
    "        backend = service.backend(backend_name)\n",
    "        noise_model = NoiseModel.from_backend(backend)\n",
    "        properties = backend.properties()\n",
    "\n",
    "        per_qubit_calib = []\n",
    "        for q in range(n_qubits):\n",
    "            t1 = properties.t1(q) or 0.0\n",
    "            t2 = properties.t2(q) or 0.0\n",
    "            readout_err = properties.readout_error(q) or 0.0\n",
    "            per_qubit_calib.append([t1/1e5, t2/1e5, readout_err])\n",
    "\n",
    "        per_gate_errors = {}\n",
    "        for g in GATE_TYPES:\n",
    "            if g == \"cx\":\n",
    "                for q0 in range(n_qubits):\n",
    "                    for q1 in range(n_qubits):\n",
    "                        if q0 != q1:\n",
    "                            try:\n",
    "                                err = properties.gate_error(\"cx\", [q0, q1])\n",
    "                            except Exception:\n",
    "                                err = 0.0\n",
    "                            per_gate_errors[f\"cx_{q0}_{q1}\"] = err\n",
    "            else:\n",
    "                for q in range(n_qubits):\n",
    "                    try:\n",
    "                        err = properties.gate_error(g, [q])\n",
    "                    except Exception:\n",
    "                        err = 0.0\n",
    "                    per_gate_errors[f\"{g}_{q}\"] = err\n",
    "\n",
    "        print(f\"Loaded noise errors from {backend_name}\")\n",
    "        return noise_model, per_qubit_calib, per_gate_errors\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load real hardware noise: {e}\")\n",
    "        per_qubit_calib = [[0.0, 0.0, 0.0] for _ in range(n_qubits)]\n",
    "        per_gate_errors = {}\n",
    "        for g in GATE_TYPES:\n",
    "            if g == \"cx\":\n",
    "                for q0 in range(n_qubits):\n",
    "                    for q1 in range(n_qubits):\n",
    "                        if q0 != q1:\n",
    "                            per_gate_errors[f\"cx_{q0}_{q1}\"] = 0.0\n",
    "            else:\n",
    "                for q in range(n_qubits):\n",
    "                    per_gate_errors[f\"{g}_{q}\"] = 0.0\n",
    "        return None, per_qubit_calib, per_gate_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a3c90ad-baef-47b8-b4cf-5cb13a18d56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration Snapshot Saving\n",
    "def save_calibration_snapshot(per_qubit_calib, per_gate_errors, n_qubits, backend_name, root='../datasets'):\n",
    "    \"\"\"\n",
    "    Save calibration snapshot as JSON in datasets/{n_qubit}-qubit/noisy/\n",
    "    Includes T1, T2, readout and per-gate errors.\n",
    "    \"\"\"\n",
    "    folder = ensure_dataset_dir(n_qubits, \"noisy\", root=root)\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    fname = f\"calibration_{n_qubits}q_noisy_{backend_name}_{timestamp}.json\"\n",
    "    path = os.path.join(folder, fname)\n",
    "    out = {\n",
    "        \"backend\": backend_name,\n",
    "        \"timestamp\": timestamp,\n",
    "        \"n_qubits\": n_qubits,\n",
    "        \"per_qubit_calib\": per_qubit_calib,\n",
    "        \"per_gate_errors\": per_gate_errors\n",
    "    }\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(out, f, indent=2)\n",
    "    print(f\"Saved calibration snapshot to {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225b9458-c6e3-403d-b4b3-272bb8d210ca",
   "metadata": {},
   "source": [
    "## Laplacian Eigenvector Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5d228ff-886c-4cf4-a871-36d3d6543b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplacian_eigenvectors_from_edge_index(edge_index, num_nodes, k=8):\n",
    "    \"\"\"\n",
    "    Compute k non-trivial Laplacian eigenvectors for a graph.\n",
    "    Returns [num_nodes, k] array. Uses dense fallback or zero padding if needed.\n",
    "    \"\"\"\n",
    "    A = np.zeros((num_nodes, num_nodes))\n",
    "    if edge_index.shape[1] > 0:\n",
    "        src, dst = edge_index\n",
    "        for i, j in zip(src, dst):\n",
    "            if i != j:\n",
    "                A[i, j] = 1.0\n",
    "\n",
    "    D = np.diag(A.sum(axis=1))\n",
    "    L = D - A\n",
    "\n",
    "    if num_nodes <= k + 1 or num_nodes <= 100:\n",
    "        try:\n",
    "            w, v = np.linalg.eigh(L)\n",
    "            return v[:, 1:k+1].astype(np.float32)\n",
    "        except Exception as e:\n",
    "            print(f\"Laplacian dense eig failed: {e}\")\n",
    "            return np.zeros((num_nodes, k), dtype=np.float32)\n",
    "\n",
    "    try:\n",
    "        ncv = min(max(2 * (k + 1), 20), num_nodes)\n",
    "        vals, vecs = eigsh(L, k=k+1, sigma=0.0, which='LM', ncv=ncv)\n",
    "        return vecs[:, 1:k+1].astype(np.float32)\n",
    "    except Exception as e:\n",
    "        print(f\"Laplacian eigsh failed: {e}\")\n",
    "        return np.zeros((num_nodes, k), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e768cd6-fe94-47d7-b787-08abdbe8e53a",
   "metadata": {},
   "source": [
    "## Circuit to Graph Conversion (DAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cf936ef-fd9b-4a95-bbac-c0d90bbee27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def circuit_to_graph(qc, per_qubit_calib, per_gate_errors, n_qubits, class_label, k_lap=8):\n",
    "\n",
    "    MAX_QUBITS = 6\n",
    "    num_lap = k_lap\n",
    "    dag = circuit_to_dag(qc)\n",
    "    nodes = list(dag.topological_op_nodes())\n",
    "    if not nodes:\n",
    "        return None\n",
    "\n",
    "    node_indices = {node: i for i, node in enumerate(nodes)}\n",
    "    num_nodes = len(nodes)\n",
    "    ops = qc.count_ops()\n",
    "    single_count = sum(ops.get(g, 0) for g in ['rx','ry','rz','h','x','y','z'])\n",
    "    two_count = ops.get('cx', 0)\n",
    "\n",
    "    edges, edge_attrs = [], []\n",
    "    for src, dst, _ in dag.edges():\n",
    "        if src not in node_indices or dst not in node_indices:\n",
    "            continue\n",
    "        i, j = node_indices[src], node_indices[dst]\n",
    "        dist = abs(i - j) / max(num_nodes - 1, 1)\n",
    "        src_gate_name = src.name.lower()\n",
    "        is_cx = 1.0 if src_gate_name == \"cx\" or dst.name.lower() == \"cx\" else 0.0\n",
    "        if src_gate_name == \"cx\" and len(src.qargs) == 2:\n",
    "            q0 = qc.find_bit(src.qargs[0]).index\n",
    "            q1 = qc.find_bit(src.qargs[1]).index\n",
    "            gate_err_key = f\"cx_{q0}_{q1}\"\n",
    "            gate_err = per_gate_errors.get(gate_err_key, 0.0)\n",
    "        else:\n",
    "            q = qc.find_bit(src.qargs[0]).index if src.qargs else 0\n",
    "            gate_err_key = f\"{src_gate_name}_{q}\"\n",
    "            gate_err = per_gate_errors.get(gate_err_key, 0.0)\n",
    "        edges.append([i, j])\n",
    "        edge_attrs.append([dist, is_cx, gate_err])\n",
    "\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).T if edges else torch.empty((2,0), dtype=torch.long)\n",
    "    edge_attr = torch.tensor(edge_attrs, dtype=torch.float) if edge_attrs else torch.empty((0,3), dtype=torch.float)\n",
    "\n",
    "    degs = [0] * num_nodes\n",
    "    for i, j in edges:\n",
    "        degs[i] += 1\n",
    "    max_deg = max(degs) or 1\n",
    "\n",
    "    feats = []\n",
    "    for idx, node in enumerate(nodes):\n",
    "        gate_name = node.name.lower()\n",
    "        qubit = qc.find_bit(node.qargs[0]).index if node.qargs else 0\n",
    "        angle = float(node.op.params[0]) if hasattr(node.op, 'params') and node.op.params else None\n",
    "        sincos = [np.sin(angle), np.cos(angle)] if angle is not None else [0.0, 0.0]\n",
    "        gate_type = one_hot_gate(gate_name)\n",
    "        qubit_onehot = [1.0 if i == qubit else 0.0 for i in range(MAX_QUBITS)]\n",
    "        calib = per_qubit_calib[qubit] if per_qubit_calib and qubit < len(per_qubit_calib) else [0.0, 0.0, 0.0]\n",
    "        if gate_name == \"cx\" and len(node.qargs) == 2:\n",
    "            q0 = qc.find_bit(node.qargs[0]).index\n",
    "            q1 = qc.find_bit(node.qargs[1]).index\n",
    "            gate_err_key = f\"cx_{q0}_{q1}\"\n",
    "            gate_err = per_gate_errors.get(gate_err_key, 0.0)\n",
    "        else:\n",
    "            gate_err_key = f\"{gate_name}_{qubit}\"\n",
    "            gate_err = per_gate_errors.get(gate_err_key, 0.0)\n",
    "        norm_layer = idx / max(num_nodes-1, 1)\n",
    "        deg_norm = degs[idx] / max_deg\n",
    "        feats.append(sincos + gate_type + qubit_onehot + calib + [gate_err, deg_norm, norm_layer])\n",
    "\n",
    "    lap_pos = laplacian_eigenvectors_from_edge_index(edge_index.numpy(), num_nodes, k=num_lap)\n",
    "    if lap_pos.shape[1] < num_lap:\n",
    "        lap_pos = np.pad(lap_pos, ((0, 0), (0, num_lap - lap_pos.shape[1])), mode='constant')\n",
    "\n",
    "    x_rows = []\n",
    "    for i, f in enumerate(feats):\n",
    "        lap = lap_pos[i] if i < len(lap_pos) else [0.0]*num_lap\n",
    "        x_rows.append(f + list(lap))\n",
    "    \n",
    "    if len(x_rows) == 0 or len(x_rows[0]) != 30:\n",
    "        return None\n",
    "\n",
    "    x = torch.tensor(x_rows, dtype=torch.float)\n",
    "\n",
    "    depth = qc.depth() / 200.0\n",
    "    cnots = two_count / 100.0\n",
    "    entangled = 1.0 if two_count > 0 else 0.0\n",
    "    single_n = single_count / 50.0\n",
    "    nN = num_nodes\n",
    "    unique_e = len(edges) / 2\n",
    "    density = unique_e / (nN*(nN-1)/2) if nN > 1 else 0.0\n",
    "    avg_calib = np.mean(np.array(per_qubit_calib), axis=0) if per_qubit_calib else [0.0, 0.0, 0.0]\n",
    "    avg_gate_err = np.mean(list(per_gate_errors.values())) if per_gate_errors else 0.0\n",
    "    u = torch.tensor([depth, cnots, entangled, single_n, density] + list(avg_calib) + [avg_gate_err], dtype=torch.float)\n",
    "\n",
    "    pos = torch.arange(num_nodes, dtype=torch.long)\n",
    "    data = Data(\n",
    "        x=x, edge_index=edge_index, edge_attr=edge_attr, pos=pos, u=u\n",
    "    )\n",
    "    data.class_label = int(class_label)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fe89a5-554b-4743-b0be-4ef74464df68",
   "metadata": {},
   "source": [
    "## Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c9a06e3-58f3-4456-a6b4-139eab8d2fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(\n",
    "    n_qubits,\n",
    "    circuit_class,\n",
    "    num_samples,\n",
    "    noise_type,\n",
    "    class_params=None,\n",
    "    backend_name=\"ibm_sherbrooke\",\n",
    "    shots=1024,\n",
    "    batch_size=100,\n",
    "    root='../datasets'\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate and save dataset for one class (classA/classB), qubit count, and noise setting.\n",
    "    Stores to datasets/{n_qubit}-qubit/{noisy|noiseless}/{classA|classB}/\n",
    "    Adds .class_label: 0 (A), 1 (B).\n",
    "    \"\"\"\n",
    "    if circuit_class == \"classA\":\n",
    "        gen_func = lambda: generate_variational_ansatz(n_qubits)\n",
    "    else:\n",
    "        gen_func = lambda: generate_qaoa_like(n_qubits)\n",
    "\n",
    "    class_label = 0 if circuit_class == \"classA\" else 1\n",
    "    noisy = (noise_type == \"noisy\")\n",
    "    noise_model, per_qubit_calib, per_gate_errors = get_noise_model_and_calib(\n",
    "        n_qubits, backend_name=backend_name, noisy=noisy)\n",
    "    simulator = AerSimulator()\n",
    "\n",
    "    data_list = []\n",
    "    for b in range((num_samples + batch_size - 1) // batch_size):\n",
    "        bs = min(batch_size, num_samples - b*batch_size)\n",
    "        before = len(data_list)\n",
    "        for _ in range(bs):\n",
    "            qc = gen_func()\n",
    "            transp = transpile(qc, basis_gates=['u1', 'u2', 'u3', 'cx'], optimization_level=0)\n",
    "            qc_meas = transp.copy()\n",
    "            qc_meas.measure_all()\n",
    "\n",
    "            if noise_model is not None:\n",
    "                job = simulator.run([qc_meas], shots=shots, noise_model=noise_model)\n",
    "            else:\n",
    "                job = simulator.run([qc_meas], shots=shots)\n",
    "            result = job.result()\n",
    "            counts = result.get_counts()\n",
    "            if isinstance(counts, list): counts = counts[0]\n",
    "\n",
    "            dim = 2 ** n_qubits\n",
    "            y_np = np.zeros(dim)\n",
    "            total = sum(counts.values())\n",
    "            for bits, c in counts.items():\n",
    "                idx = int(bits.replace(' ', '')[::-1], 2)\n",
    "                y_np[idx] = c / total\n",
    "            eps = 1e-6\n",
    "            y_np = (1 - eps) * y_np + eps / dim\n",
    "            y = torch.tensor(y_np, dtype=torch.float)\n",
    "\n",
    "            graph_data = circuit_to_graph(qc, per_qubit_calib, per_gate_errors, n_qubits, class_label, k_lap=8)\n",
    "            if graph_data is None: continue\n",
    "            graph_data.y = y\n",
    "            data_list.append(graph_data)\n",
    "        generated = len(data_list) - before\n",
    "        print(f\"Batch {b+1} Generated {generated} samples for {n_qubits}q, {noise_type}, {circuit_class}\")\n",
    "\n",
    "    save_dataset(data_list, n_qubits, noise_type, circuit_class, root=root)\n",
    "    return data_list, (per_qubit_calib, per_gate_errors) if noisy else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2367b39-5541-4fa7-922a-aafe74cf62a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_6q_extrapolation_data(\n",
    "    num_samples_per_class=500,\n",
    "    shots=1024,\n",
    "    backend_name=\"ibm_sherbrooke\",\n",
    "    overwrite=False,\n",
    "    root='../datasets'\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate extrapolation datasets for 6-qubit circuits across:\n",
    "      - Class A and Class B\n",
    "      - Noiseless and noisy conditions\n",
    "    Saves to: ../datasets/6-qubit/{noisy|noiseless}/{classA|classB}/\n",
    "    \"\"\"\n",
    "    n_qubits = 6\n",
    "    circuit_classes = {\"classA\": {}, \"classB\": {}}\n",
    "    noise_types = [\"noiseless\", \"noisy\"]\n",
    "    batch_size = 100\n",
    "    result_dict = {}\n",
    "\n",
    "    # Save calibration snapshot\n",
    "    if \"noisy\" in noise_types:\n",
    "        folder = ensure_dataset_dir(n_qubits, \"noisy\", circuit_class=None, root=root)\n",
    "        existing = [f for f in os.listdir(folder) if f.startswith(\"calibration_\")]\n",
    "        if not existing or overwrite:\n",
    "            _, per_qubit_calib, per_gate_errors = get_noise_model_and_calib(n_qubits, noisy=True)\n",
    "            save_calibration_snapshot(per_qubit_calib, per_gate_errors, n_qubits, backend_name, root=root)\n",
    "\n",
    "    for noise_type in noise_types:\n",
    "        for circuit_class, class_params in circuit_classes.items():\n",
    "            folder = ensure_dataset_dir(n_qubits, noise_type, circuit_class, root=root)\n",
    "            fname = f\"dataset_{n_qubits}q_{noise_type}_{circuit_class}.pt\"\n",
    "            save_path = os.path.join(folder, fname)\n",
    "\n",
    "            print(f\"\\n6Q Generating {circuit_class}, {noise_type}\")\n",
    "            dataset, _ = generate_dataset(\n",
    "                n_qubits=n_qubits,\n",
    "                circuit_class=circuit_class,\n",
    "                num_samples=num_samples_per_class,\n",
    "                noise_type=noise_type,\n",
    "                class_params=class_params,\n",
    "                backend_name=backend_name,\n",
    "                shots=shots,\n",
    "                batch_size=batch_size,\n",
    "                root=root\n",
    "            )\n",
    "            result_dict[(noise_type, circuit_class)] = dataset\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09f80f7e-0632-43eb-9ff5-fd9dbb7b2c2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded noise errors from ibm_sherbrooke\n",
      "Saved calibration snapshot to ../datasets\\6-qubit\\noisy\\calibration_6q_noisy_ibm_sherbrooke_20250716_200853.json\n",
      "\n",
      "6Q Generating classA, noiseless\n",
      "Batch 1 Generated 100 samples for 6q, noiseless, classA\n",
      "Batch 2 Generated 100 samples for 6q, noiseless, classA\n",
      "Batch 3 Generated 100 samples for 6q, noiseless, classA\n",
      "Batch 4 Generated 100 samples for 6q, noiseless, classA\n",
      "Batch 5 Generated 100 samples for 6q, noiseless, classA\n",
      "Saved dataset (500 samples) to ../datasets\\6-qubit\\noiseless\\classA\\dataset_6q_noiseless_classA.pt\n",
      "\n",
      "6Q Generating classB, noiseless\n",
      "Batch 1 Generated 100 samples for 6q, noiseless, classB\n",
      "Batch 2 Generated 100 samples for 6q, noiseless, classB\n",
      "Batch 3 Generated 100 samples for 6q, noiseless, classB\n",
      "Batch 4 Generated 100 samples for 6q, noiseless, classB\n",
      "Batch 5 Generated 100 samples for 6q, noiseless, classB\n",
      "Saved dataset (500 samples) to ../datasets\\6-qubit\\noiseless\\classB\\dataset_6q_noiseless_classB.pt\n",
      "\n",
      "6Q Generating classA, noisy\n",
      "Loaded noise errors from ibm_sherbrooke\n",
      "Batch 1 Generated 100 samples for 6q, noisy, classA\n",
      "Batch 2 Generated 100 samples for 6q, noisy, classA\n",
      "Batch 3 Generated 100 samples for 6q, noisy, classA\n",
      "Batch 4 Generated 100 samples for 6q, noisy, classA\n",
      "Batch 5 Generated 100 samples for 6q, noisy, classA\n",
      "Saved dataset (500 samples) to ../datasets\\6-qubit\\noisy\\classA\\dataset_6q_noisy_classA.pt\n",
      "\n",
      "6Q Generating classB, noisy\n",
      "Loaded noise errors from ibm_sherbrooke\n",
      "Batch 1 Generated 100 samples for 6q, noisy, classB\n",
      "Batch 2 Generated 100 samples for 6q, noisy, classB\n",
      "Batch 3 Generated 100 samples for 6q, noisy, classB\n",
      "Batch 4 Generated 100 samples for 6q, noisy, classB\n",
      "Batch 5 Generated 100 samples for 6q, noisy, classB\n",
      "Saved dataset (500 samples) to ../datasets\\6-qubit\\noisy\\classB\\dataset_6q_noisy_classB.pt\n",
      "\n",
      "6-Qubit Extrapolation Dataset Summary:\n",
      "  noiseless/classA: 500 samples\n",
      "  noiseless/classB: 500 samples\n",
      "  noisy/classA: 500 samples\n",
      "  noisy/classB: 500 samples\n"
     ]
    }
   ],
   "source": [
    "EXTRAP_SAMPLES = 500\n",
    "SHOTS = 1024\n",
    "BACKEND = \"ibm_sherbrooke\"\n",
    "\n",
    "extrap_data = generate_6q_extrapolation_data(\n",
    "    num_samples_per_class=EXTRAP_SAMPLES,\n",
    "    shots=SHOTS,\n",
    "    backend_name=BACKEND,\n",
    "    overwrite=False\n",
    ")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n6-Qubit Extrapolation Dataset Summary:\")\n",
    "for (noise_type, circuit_class), data_list in extrap_data.items():\n",
    "    print(f\"  {noise_type}/{circuit_class}: {len(data_list)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca2eb68-690f-4e20-a416-896905dd834b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
